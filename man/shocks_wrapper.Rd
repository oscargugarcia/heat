% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/shocks_main.R
\name{shocks_wrapper}
\alias{shocks_wrapper}
\title{Wrapper function for shock estimation}
\usage{
shocks_wrapper(
  pol_date_pairs,
  conditions_list,
  geom_id_col_parquet,
  geom_id_col_df,
  date_id_col_df,
  window,
  start,
  hist_lags,
  align,
  bin_width,
  window_spec,
  disjoint,
  int_threshold,
  prop_cores,
  max_group_size,
  query,
  output_path,
  error_log_path,
  start_date = NULL,
  stop_date = NULL,
  met_cols = c("trans_type", "trans_var"),
  date_tolerance_days = 10
)
}
\arguments{
\item{pol_date_pairs}{A dataframe with unique geometry id and date pairs. The geometry IDs must correspond to those
in the parquet file with climate measures. Dates must be in date format (eg: "YYYY-MM-DD").}

\item{conditions_list}{A named list of conditions to query the parquet file with climate measures. The names conditions
should be:
1. data_path: A character string with the path to the parquet file.
2. geom_id: A vector of unique geometry IDs.
3. trans_type: A character string indicating the type of transformations to be included (e.g., "polynomial").
4. trans_var: A character string indicating the degrees of the transformation to include.
5. product_temp_res: A character indicating the temporal resolution of the product. Must be one of the following: "daily" or "monthly" ("yearly" not supported yet).}

\item{window}{An integer indicating the length of the data sequence (i.e., the number of tempora units in the data sequence, such as the number of days).}

\item{int_threshold}{A float number indicating the minimum threshold that date sequences must intersect with the date columns in the parquet file to be considered valid.}

\item{met_cols}{A vector of columns names in the parquet file that are used as metadata columns.}

\item{geom_id_col_parquet:}{a character string indicating the name of the column in the parquet file that identifies the geometries}

\item{geom_id_col_df:}{a character string indicating the name of the column in the that identifies the geometries}

\item{date_id_col_df:}{a character string indicating the name of the column in the dataframe that identifies the dates}

\item{start:}{An integer indicating the offset in days with respect to the date polygon date.}

\item{hist_lags:}{An integer indicating the number of years to construct the historical baseline. Required if window_spec is "dynamic" or "both".}

\item{align:}{A character string indicating whether the sequence is left- or right-aligned with respect to the polygon date.
Left-alignment means that the sequence contains dates AFTER the polygon date. Right-alingment means that the sequence includes dates BEFORE the polygon date.}

\item{bin_width:}{An integer indicating the number of days in each temporal bin that divides the date sequence (e.g., 30 means each bin contains 30 days).}

\item{disjoint:}{A boolean indicating whether the bins are disjoint or overlapping. Default is overlapping (disjoint = FALSE).}

\item{window_spec:}{A character string indicating whether the historical baseline is dynamic, fixed or both. Must be either "dynamic", "fixed", or "both".}

\item{start_date:}{A character string in date format ("YYYY-MM-DD") indicating the start date of the historical window. Only required if window_spec= "dynamic" or window_spec="both".}

\item{stop_date:}{A character string in date format ("YYYY-MM-DD") indicating the end date of the historical window. Only required if window_spec= "dynamic" or window_spec="both".}

\item{max_group_size:}{A integer indicating the maximum number of polygons in each processing group.}

\item{date_tolerance_days:}{An integer indicating the maximum number of dates that two polygon interviews should be apart to consider them part of two different polygon groups.}

\item{prop_cores:}{A float unmber indicating the proportion of cores to use for parallelization.}

\item{query:}{A character string with the name given to the output.}

\item{output_path:}{A character string with the path to the folder where the output should be stored.}

\item{error_log_path:}{A character string with the path to the folder where the error logs are stored.}
}
\value{
A list containing the output path and the error logs path. A NULL is returned if a fatal error prevented any estimation from taking place (e.g., the function failed).
If the output path is NULL, an error was produced when generating the climate shock measures and no valid estimates were created.
If the error logs list is NULL, no errors or anomalies (i.e., check details) were recorded.
}
\description{
Wrapper function to estimates deviations in climate exposure relative to a baseline
}
\details{
The function performs the following operations:
\itemize{
\item Input validation
\item Groups polygons by date proximity. This helps decrease the size of the parquet query (i.e., polygons with dates close to each other share date columns, reducing the number of total columns)
\item Executes the estimation of exposure to climate shocks
\item Produces error logs, which register different kinds of anomalies. Check below.
\item Saves error logs and the results in a long format.
\item The error logs register the following anomalies:
\enumerate{
\item Dates not in the productÂ´s range
\item Not enough data to build historical baselines (according to the int_threshold parameter), and
\item Missing data in the parquet files.
}
}
}
